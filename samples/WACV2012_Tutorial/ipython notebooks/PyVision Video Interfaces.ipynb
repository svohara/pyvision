{
 "metadata": {
  "name": "PyVision Video Interfaces"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PyVision Video Interface Demonstration\n",
      "==========\n",
      "\n",
      "Demonstration of the various video classes\n",
      "and common interfaces for controlling and\n",
      "viewing output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import pyvision as pv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vid_file = pv.TAZ_VIDEO  #built-in sample video in PyVision\n",
      "vid = pv.Video(vid_file)\n",
      "type(vid)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "pyvision.types.Video.Video"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A video is an iterable object. You can play a video in two easy ways.\n",
      "\n",
      "- By iterating over the frames, displaying each to the same window.\n",
      "\n",
      "- The second is by using the built-in play() method, which comes with some nifty features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for f in vid:\n",
      "    f.show(delay=33, window=\"Demo\")  #delay is ms to pause before next image is shown.\n",
      "\n",
      "vid.play(delay=33, window=\"Demo\")  #33 millisec delay is about 30 fps."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "92"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The *play()* method allows the user to pause-and-play the video,\n",
      "step through frames, or abort early. It also annotates the frame\n",
      "number in the upper left, and can call a callback function.\n",
      "\n",
      "The video will start paused if delay=0, so the user should highlight\n",
      "the playback window and press the \"s\" key to step to the next frame.\n",
      "When doing so, the iPython Notebook will display the text menu for\n",
      "the pause-and-play interface."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vid.play(delay=0, window=\"Demo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A **VideoMontage** is a set of videos that can be played at once in the same screen.\n",
      "We use a dictionary as the collection of videos, which are sorted based on the keys.\n",
      "All videos will play until completion. Shorter videos will halt on the last frame until the others finish."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "test_dir = os.path.dirname(vid_file)  #in the same directory as the TAZ video there are two others\n",
      "vid_cars = pv.Video( os.path.join(test_dir,\"toy_car.m4v\"))  #toy cars on a carpet\n",
      "vid_bug = pv.Video( os.path.join(test_dir,\"BugsSample.m4v\")) #a bug in grass\n",
      "vid_taz = pv.Video(vid_file) #taz video\n",
      "videoM = pv.VideoMontage( {1:vid_cars, 2:vid_bug, 3:vid_taz}, layout=(1,3), tileSize=(200,200))\n",
      "videoM.play(delay=33, window=\"Demo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "All Videos in the Video Montage Have Completed.\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "175"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A VideoMontage object can be treated itself like a video, and thus embedded in another montage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vid1 = pv.Video(vid_file)\n",
      "vid2 = pv.Video(vid_file)\n",
      "vid3 = pv.Video(vid_file)\n",
      "videoM1 = pv.VideoMontage( {1:vid1, 2:vid2}, layout=(2,1), tileSize=(133,100))\n",
      "videoM2 = pv.VideoMontage( {1:videoM1, 2:vid3}, layout=(1,2), tileSize=(266,200)) #a montage within a montage\n",
      "videoM2.play(delay=33, window=\"Demo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "All Videos in the Video Montage Have Completed.\n",
        "All Videos in the Video Montage Have Completed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "94"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "There is an abstract **VideoInterface** class that defines the `play()` method,\n",
      "the pause-and-play interface, and represents videos as iterables.\n",
      "\n",
      "The following classes all implement the VideoInterface:\n",
      "\n",
      "* Video\n",
      "* VideoMontage\n",
      "* VideoFromImages     - For using a directory of images as a video\n",
      "* VideoFromFileList   - For using a list of image file names for a video\n",
      "* VideoFromImageStack - For using a stack of numpy arrays as a video\n",
      "* Webcam"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vid = pv.Webcam()\n",
      "vid.play(window=\"Demo\", delay=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PAUSED: Select <a>bort program, <q>uit playback, <c>ontinue playback, or <s>tep to next frame.\n",
        "PAUSED: Select <a>bort program, <q>uit playback, <c>ontinue playback, or <s>tep to next frame."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "125"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**ImageBuffer** is a useful class for buffering a set of pyvision images.\n",
      "ImageBuffers can be used to buffer video playback, to transform a set\n",
      "of grayscale images into an image stack, among other uses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyvision as pv\n",
      "import cv2.cv as cv\n",
      "\n",
      "imgBuffer = pv.ImageBuffer(N=25)\n",
      "vid = pv.Video(\"./seq3.avi\")\n",
      "vid.play(window=\"Demo\",delay=20,imageBuffer=imgBuffer)  #play() method supports a buffer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "PAUSED: Select <a>bort program, <q>uit playback, <c>ontinue playback, or <s>tep to next frame.\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "141"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#the most recent images will be in the buffer\n",
      "imgBuffer.show(window=\"Demo\", delay=0) #simple way to view buffer\n",
      "cv.DestroyWindow(\"Demo\")  #kill the window if we don't need it anymore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#use an image montage if you want greater layout control\n",
      "montage = imgBuffer.asMontage(layout=(3,5))\n",
      "montage.show(window=\"Demo\")\n",
      "cv.DestroyWindow(\"Demo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can convert an ImageBuffer to a 3D numpy array representing a \"stack\" of grayscale images.\n",
      "This can be convenient for performing numpy matrix operations on all images in the stack."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we can convert the buffer to an numpy grayscale image stack\n",
      "(w,h) = imgBuffer[0].size \n",
      "imstack = imgBuffer.asStackBW(size=(w/2, h/2))\n",
      "print type(imstack)\n",
      "vid2 = pv.VideoFromImageStack(imstack)  #we can playback an image stack as a video\n",
      "vid2.play(window=\"Demo\", delay=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<type 'numpy.ndarray'>\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "24"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#because an image stack is a numpy array, operations like thresholding all\n",
      "# images in the grayscale video is very easy.\n",
      "imstack2 = (imstack < 100)*255.0\n",
      "vid3 = pv.VideoFromImageStack(imstack2)\n",
      "vid3.play(window=\"Demo\", delay=60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "24"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "cv.DestroyAllWindows()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}